# Algoritmos Embarazosamente Paralelos con OpenMP

Este proyecto contiene implementaciones de algoritmos embarazosamente paralelos (embarrassingly parallel) utilizando OpenMP en C++.

## ğŸ“š Â¿QuÃ© son los algoritmos embarazosamente paralelos?

Son problemas que pueden ser divididos en tareas completamente independientes, donde cada tarea no requiere comunicaciÃ³n con las demÃ¡s. Son ideales para paralelizaciÃ³n porque:
- âœ… No hay dependencias entre tareas
- âœ… No requieren sincronizaciÃ³n compleja
- âœ… Escalan linealmente con el nÃºmero de procesadores
- âœ… ImplementaciÃ³n simple y directa

**Ejemplos del mundo real:**
- Procesar mÃºltiples imÃ¡genes con el mismo filtro
- Renderizar frames independientes de video
- CÃ¡lculos cientÃ­ficos sobre datasets independientes
- ValidaciÃ³n de mÃºltiples entradas de datos

## ğŸ¯ Ejercicios Implementados

### Ejercicio 1: Filtro a MÃºltiples ImÃ¡genes
**Archivo:** `ejercicio1_filtro_imagenes.cpp`

Aplica un filtro blanco y negro a mÃºltiples imÃ¡genes en paralelo. Cada imagen se procesa independientemente.

**CaracterÃ­sticas:**
- ğŸ–¼ï¸ Simula procesamiento de 8 imÃ¡genes de 800x600 pÃ­xeles
- ğŸ¨ Aplica filtro de threshold para blanco/negro (valor > 128 â†’ blanco, sino â†’ negro)
- âš¡ Cada thread procesa una imagen completa
- ğŸ“Š Cada pÃ­xel se convierte independientemente

**ParalelizaciÃ³n:** `#pragma omp parallel for` sobre el bucle de imÃ¡genes

---

### Ejercicio 3: Suma de Elementos en MÃºltiples Vectores
**Archivo:** `ejercicio3_suma_vectores.cpp`

Calcula la suma de elementos en mÃºltiples vectores de forma paralela.

**CaracterÃ­sticas:**
- ğŸ“ Procesa 10 vectores de 1,000,000 de elementos cada uno
- ğŸ”¢ Cada vector contiene nÃºmeros aleatorios entre 0-99
- âš¡ Cada vector se suma independientemente (sin reducciÃ³n compartida)
- ğŸ’¾ Resultados almacenados en vector de resultados

**ParalelizaciÃ³n:** `#pragma omp parallel for` sobre vectores independientes

---

### Ejercicio 4: BÃºsqueda en MÃºltiples Vectores
**Archivo:** `ejercicio4_busqueda_vectores.cpp`

Busca un valor especÃ­fico en mÃºltiples vectores simultÃ¡neamente.

**CaracterÃ­sticas:**
- ğŸ” Busca el valor 42 en 8 vectores de 500,000 elementos
- ğŸ“ Reporta si el valor fue encontrado y en quÃ© posiciÃ³n
- ğŸ² El valor se inserta aleatoriamente en algunos vectores
- âš¡ Cada bÃºsqueda es completamente independiente (bÃºsqueda lineal)

**ParalelizaciÃ³n:** `#pragma omp parallel for` sobre bÃºsquedas independientes

---

### Ejercicio 5: SimulaciÃ³n de CaÃ­da Libre
**Archivo:** `ejercicio5_caida_libre.cpp`

Simula la caÃ­da libre de mÃºltiples objetos desde diferentes alturas (sin resistencia del aire).

**CaracterÃ­sticas:**
- ğŸª Calcula el tiempo de caÃ­da para 8 objetos diferentes
- ğŸ“ Usa la fÃ³rmula fÃ­sica: **t = âˆš(2h/g)** donde g = 9.81 m/sÂ²
- ğŸ’¨ Calcula tambiÃ©n la velocidad final de impacto: **v = g Ã— t**
- ğŸ“Š Muestra estadÃ­sticas: objeto mÃ¡s lento y mÃ¡s rÃ¡pido
- ğŸ¯ Objetos: pelota de tenis, martillo, pluma, ladrillo, balÃ³n, moneda, libro, gota de agua

**ParalelizaciÃ³n:** `#pragma omp parallel for` sobre cÃ¡lculos independientes de fÃ­sica

## ğŸ³ EjecuciÃ³n en Docker (Recomendado)

### OpciÃ³n 1: Usando el contenedor japeto/parallel-tools

```bash
# Iniciar el contenedor con volumen montado
docker run -it -v "${PWD}:/home/japeto/app:rw" -w /home/japeto/app japeto/parallel-tools:v64 bash

# Dentro del contenedor, compilar todos los ejercicios
g++ -fopenmp ejercicio1_filtro_imagenes.cpp -o ejercicio1 && \
g++ -fopenmp ejercicio3_suma_vectores.cpp -o ejercicio3 && \
g++ -fopenmp ejercicio4_busqueda_vectores.cpp -o ejercicio4 && \
g++ -fopenmp ejercicio5_caida_libre.cpp -o ejercicio5

# Ejecutar todos los ejercicios
./ejercicio1
./ejercicio3
./ejercicio4
./ejercicio5

# O ejecutar todos en secuencia
./ejercicio1 && echo "" && ./ejercicio3 && echo "" && ./ejercicio4 && echo "" && ./ejercicio5
```

### OpciÃ³n 2: Comando Ãºnico (ejecutar y salir)

```bash
docker run --rm -v "${PWD}:/home/japeto/app:rw" -w /home/japeto/app japeto/parallel-tools:v64 bash -c \
  "g++ -fopenmp ejercicio1_filtro_imagenes.cpp -o ejercicio1 && \
   g++ -fopenmp ejercicio3_suma_vectores.cpp -o ejercicio3 && \
   g++ -fopenmp ejercicio4_busqueda_vectores.cpp -o ejercicio4 && \
   g++ -fopenmp ejercicio5_caida_libre.cpp -o ejercicio5 && \
   echo '=== EJECUTANDO TODOS LOS EJERCICIOS ===' && \
   ./ejercicio1 && echo '' && ./ejercicio3 && echo '' && ./ejercicio4 && echo '' && ./ejercicio5"
```

---

## ğŸ’» CompilaciÃ³n Local (sin Docker)

### Windows (con MinGW)
```powershell
g++ -fopenmp ejercicio1_filtro_imagenes.cpp -o ejercicio1.exe
g++ -fopenmp ejercicio3_suma_vectores.cpp -o ejercicio3.exe
g++ -fopenmp ejercicio4_busqueda_vectores.cpp -o ejercicio4.exe
g++ -fopenmp ejercicio5_caida_libre.cpp -o ejercicio5.exe
```

**Ejecutar:**
```powershell
.\ejercicio1.exe
.\ejercicio3.exe
.\ejercicio4.exe
.\ejercicio5.exe
```

### Linux/Mac
```bash
g++ -fopenmp ejercicio1_filtro_imagenes.cpp -o ejercicio1
g++ -fopenmp ejercicio3_suma_vectores.cpp -o ejercicio3
g++ -fopenmp ejercicio4_busqueda_vectores.cpp -o ejercicio4
g++ -fopenmp ejercicio5_caida_libre.cpp -o ejercicio5
```

**Ejecutar:**
```bash
./ejercicio1
./ejercicio3
./ejercicio4
./ejercicio5
```

## âš™ï¸ ConfiguraciÃ³n de Threads

Para controlar el nÃºmero de threads que usa OpenMP:

### En Docker/Bash:
```bash
export OMP_NUM_THREADS=4
./ejercicio1
```

### En PowerShell (Windows):
```powershell
$env:OMP_NUM_THREADS=4
.\ejercicio1.exe
```

### En CMD (Windows):
```cmd
set OMP_NUM_THREADS=4
ejercicio1.exe
```

### Dentro del contenedor Docker:
```bash
# Iniciar contenedor con variable de entorno
docker run -it -e OMP_NUM_THREADS=8 -v "${PWD}:/home/japeto/app:rw" -w /home/japeto/app japeto/parallel-tools:v64 bash
```

**RecomendaciÃ³n:** Usar un nÃºmero de threads igual al nÃºmero de cores fÃ­sicos de tu CPU para mejor rendimiento.

## ğŸ“– Conceptos de OpenMP Utilizados

### Directivas de ParalelizaciÃ³n

| Directiva | DescripciÃ³n | Uso en el Proyecto |
|-----------|-------------|-------------------|
| `#pragma omp parallel for` | Paraleliza un bucle for distribuyendo las iteraciones entre threads | Todos los ejercicios - itera sobre tareas independientes |
| `#pragma omp critical` | SecciÃ³n crÃ­tica para evitar condiciones de carrera | Protege la salida por consola |

### Funciones de OpenMP

| FunciÃ³n | DescripciÃ³n | Ejemplo de Uso |
|---------|-------------|----------------|
| `omp_get_wtime()` | Obtiene el tiempo actual en segundos (alta precisiÃ³n) | Medir tiempo de ejecuciÃ³n |
| `omp_get_thread_num()` | Obtiene el ID del thread actual (0 a N-1) | Identificar quÃ© thread ejecuta cada tarea |
| `omp_get_max_threads()` | Obtiene el nÃºmero mÃ¡ximo de threads disponibles | Reportar configuraciÃ³n al usuario |

### Modelo de EjecuciÃ³n

```
SECUENCIAL:                    PARALELO (4 threads):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”          Thread 0: â–ˆâ–ˆâ–ˆâ–ˆ
Tarea 1                        Thread 1: â–ˆâ–ˆâ–ˆâ–ˆ
Tarea 2                        Thread 2: â–ˆâ–ˆâ–ˆâ–ˆ
Tarea 3                        Thread 3: â–ˆâ–ˆâ–ˆâ–ˆ
Tarea 4                        
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”          â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Tiempo: 4T                     Tiempo: T (speedup 4x)
```

## ğŸš€ Ventajas de la ParalelizaciÃ³n

Estos ejercicios demuestran cÃ³mo la paralelizaciÃ³n puede acelerar significativamente el procesamiento cuando:

âœ… **Las tareas son independientes** - No hay dependencias de datos entre iteraciones  
âœ… **No hay necesidad de compartir datos** - Cada tarea trabaja en su propio espacio de memoria  
âœ… **El costo computacional es significativo** - El tiempo de procesamiento justifica el overhead de threads  
âœ… **Hardware multi-core disponible** - Aprovecha procesadores modernos con mÃºltiples cores  

### Speedup Esperado

| Threads | Speedup TeÃ³rico | Speedup Real (aprox) |
|---------|----------------|---------------------|
| 1 | 1x | 1x |
| 2 | 2x | 1.8x - 1.9x |
| 4 | 4x | 3.5x - 3.8x |
| 8 | 8x | 6.5x - 7.5x |

**Nota:** El speedup real es menor debido a:
- Overhead de creaciÃ³n y sincronizaciÃ³n de threads
- Limitaciones de memoria cache
- ContenciÃ³n de recursos compartidos (memoria, I/O)

## ğŸ“Š Resultados Esperados

### Ejemplo de Salida (Ejercicio 1):
```
=== EJERCICIO 1: Filtro a MÃºltiples ImÃ¡genes ===
Creando 8 imÃ¡genes...
Thread 2 procesando imagen: imagen_2.jpg
Thread 0 procesando imagen: imagen_0.jpg
Thread 3 procesando imagen: imagen_3.jpg
Thread 1 procesando imagen: imagen_1.jpg
...
Todas las imÃ¡genes procesadas en 0.245 segundos
NÃºmero de threads utilizados: 4
```

### Ejemplo de Salida (Ejercicio 5):
```
=== EJERCICIO 5: SimulaciÃ³n de CaÃ­da Libre ===
Thread 1 calculando: Martillo
Thread 0 calculando: Pelota de tenis
...
--- Pelota de tenis ---
  Altura inicial: 10.000 m
  Masa: 0.058 kg
  Tiempo de caÃ­da: 1.428 segundos
  Velocidad al impactar: 14.012 m/s
...
Tiempo de cÃ³mputo: 0.001 segundos
NÃºmero de threads utilizados: 4
```

## ğŸ“ Notas Importantes

- ğŸ¯ Las "imÃ¡genes" en el Ejercicio 1 son **simuladas** (estructuras en memoria), no archivos .jpg reales
- â±ï¸ Los tiempos de ejecuciÃ³n variarÃ¡n segÃºn el hardware
- ğŸ”„ El speedup ideal es lineal con el nÃºmero de cores, pero en prÃ¡ctica es menor
- ğŸ³ **Docker es la forma recomendada** para ejecutar (entorno consistente)
- ğŸ’¾ Los binarios compilados (`ejercicio1`, `ejercicio3`, etc.) se crean en el directorio actual

## ğŸ”§ Troubleshooting

### Error: "command not found: g++"
**SoluciÃ³n:** Usa el contenedor Docker que ya tiene GCC instalado.

### Error: "undefined reference to omp_*"
**SoluciÃ³n:** AsegÃºrate de compilar con `-fopenmp`

### Los threads no se distribuyen
**SoluciÃ³n:** Verifica `OMP_NUM_THREADS` o el nÃºmero de cores disponibles

### Rendimiento bajo en Docker
**SoluciÃ³n:** Aumenta los recursos asignados a Docker (CPU/memoria)
